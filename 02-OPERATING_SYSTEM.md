## 운영체제

<details>
  <summary><h3>1. 시스템 콜이 무엇인지 설명해 주세요.</h3></summary>
<ul>
<li> 우리가 사용하는 시스템 콜의 예시를 들어주세요.</li>
<li> 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.</li>
<li> 시스템 콜의 유형에 대해 설명해 주세요.</li>
<li> 운영체제의 Dual Mode 에 대해 설명해 주세요.</li>
<li> 왜 유저모드와 커널모드를 구분해야 하나요? </li>
<li> 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>2. 인터럽트가 무엇인지 설명해 주세요.</h3></summary>
<ul>
<li> 인터럽트는 어떻게 처리하나요?</li>
<li> Polling 방식에 대해 설명해 주세요.</li>
<li> HW / SW 인터럽트에 대해 설명해 주세요.</li>
<li> 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요? </li>
</ul>
</details>

<details>
  <summary><h3>3. 프로세스가 무엇인가요?</h3></summary>
  <strong>프로세스란 실행 중인 프로그램을 의미하며, 코드뿐 아니라 해당 코드의 실행에 필요한 메모리 공간, CPU 상태, 입출력 정보, 운영체제 자원 등을 포함하는 작업 단위입니다.</strong>
  <ul>
    <li>프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.</li>    
    <strong>프로그램은 정적인 코드의 집합이며, 프로세스는 실행 중인 프로그램으로 메모리 공간과 시스템 자원을 독립적으로 할당받습니다.  
    스레드는 프로세스 내 OS의 스케줄러에 의해 코드가 실행되는 실질적 프로그램 실행 단위입니다.</strong>    
    <li>PCB가 무엇인가요?</li>    
   <strong>PCB(Process Control Block)는 OS가 프로세스 스케줄링을 위해 프로세스에 관한 모든 정보를 가지고 있는 블록으로서 특정 프로세스를 관리하기 위해 사용하는 커널의 자료구조입니다.  
    프로세스의 ID, 상태, 프로그램 카운터, 레지스터 정보, 스케줄링 정보, 메모리 할당 정보 등이 저장되어 있습니다.</strong>
    <li>그렇다면, 스레드는 PCB를 갖고 있을까요?</li>    
    <strong>스레드는 PCB를 갖는 대신, TCB(Thread Control Block) 경량 프로세스의 별도 제어블록을 통해 관리됩니다.  
    이때 스레드는 동일한 프로세스의 주소 공간을 공유하므로 메모리 관련 정보는 공통적으로 참조합니다.</strong>
    <li>리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?</li>    
    <strong>fork() 명령어를 통해 부모 프로세스의 복제본을 생성합니다.  
    이후 pthread_create() 혹은 clone()를 통한 호출에 의해 생성되며, 커널에서 스레드는 프로세스의 한 종류로 인식되어 task_struct를 기반으로 하여 관리됩니다.</strong>
    <li>자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?</li>    
    <strong>자식 프로세스가 상태를 알리지 않고 종료되는 경우에는 좀비 프로세스가 되며 커널에서 종료된 자식 프로세스에 대한 최소한의 정보를 저장(부모 프로세스에서 활용할 수 있으므로)하고 있게 됩니다.  
    좀비 프로세스로 인한 메모리 낭비를 막기 위해 부모 프로세스에서 wait 시스템 콜을 이용해 자식 프로세스의 종료 상태를 회수하게 되면 좀비 프로세스를 제거할 수 있습니다.  
    부모 프로세스가 먼저 종료되면 자식 프로세스는 고아 프로세스가 되며, 이때 부모 프로세스는 시스템이 시작될 때 생성되는 init 프로세스(pid=1, 유닉스 계열은 데몬 프로세스)가 새로운 부모 프로세스가 되며  
    고아 프로세스가 작업을 종료하면 wait 시스템 콜로 종료 상태를 회수하여 좀비 프로세스가 되는 것을 방지합니다.</strong>
    <li>리눅스에서, 데몬프로세스에 대해 설명해 주세요.</li>    
    <strong>데몬프로세스는 백그라운드에서 실행되는 프로그램으로, 사용자가 직접적으로 제어하지 않고 백그라운드에서 돌면서 여러 작업을 하는 프로그램을 의미합니다.  
    사용자의 요청을 기다리고 있다가 요청이 발생하면 이에 적절히 대응하는 리스너와 같은 역할을 하며, 메모리에 상주하면서 특정 요청이 오면 즉시 대응 할 수 있도록 대기중인 프로세스입니다.</strong>
    <li>리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.</li>    
    <strong>리눅스에서 프로세스 트리의 루트 노드는 init 프로세스입니다. init 프로세스는 시스템 부팅 시에 가장 먼저 실행되는 프로세스로, 나머지 모든 프로세스는 init의 자손이거나 자식 프로세스라고 볼 수 있습니다.</strong>
  </ul>
</details>


<details>
  <summary><h3>4. 프로세스 주소공간에 대해 설명해 주세요.</h3></summary>
  프로세스는 코드가 저장되어 읽기 전용이며 실행권한이 있는 text, 
  초기값이 명시된 전역변수 및 정적변수가 저장되는 data, 
  초기화 되지 않는 전역변수 및 정적변수가 저장되는BSS, 
  동적 메모리 할당을 위해 크기가 가변적으로 변하며 런타임시 생성되는 객체의 저장공간heap, 
  함수 호출시 생성되는 지역변수, 리턴주소, 매개변수가 저장되며 함수의 호출이 종료시 자동으로 종료되는stack으로 나뉩니다.
<ul>
<li> 초기화 하지 않은 변수들은 어디에 저장될까요?</li>
  초기화되지 않은 지역 or 전역변수는 BSS(Block Started by Symbol) 영역에 저장되어 os에서 실행시 0으로 초기화됩니다.
<li> 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?</li>
  Stack과 Heap은 크기가 가변적으로 변하는 성질을 가지고 있습니다. 
  Heap의 경우, 개발자가 malloc() 함수 혹은 new 명령어와 같이 동적 메모리 할당 명령어를 통해 확장됩니다.
  Stack의 경우, 함수 호출시 자동으로 메모리가 할당되며, Return 실행시 소멸됩니다.
  두 주소공간 모두 OS에서 설정된 한계치를 초과시, Stack Overflow, heap out of memory와 같은 오류가 발생합니다.
<li> Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?</li>
  Stack은 연속된 메모리 블록을 사용하며, LIFO(Last In First Out)방식의 메모리 구조를 통해 함수호출시 컴파일러에 의해 정적 분석이 가능하여 메모리 접근이 빠르고 효율적입니다.
  Heap의 경우 Runtime시 동적으로 할당되어 포인터 기반의 접근이 많아 할당과 해제에 대한 연산이 추가되어야 하는 제약이 존재하여 속도가 상대적으로 느립니다.
<li> 다음과 같이 공간을 분할하는 이유가 있을까요?</li>
  1. 메모리 충돌 방지를 통한 안정성 향상
  2. Code & Data의 접근 권한 분리
  3. 동적 할당 메커니즘과 함수 호출 스택의 독립적 운영.
  4. 메모리 보호와 보안성 강화
  5. Thread간 독립적인 스택 공간 구성 가능
<li> 스레드의 주소공간은 어떻게 구성되어 있을까요?</li>
  하나의 프로세스 내에 존재하는 여러 스레드는 같은 주소 공간을 공유하므로, 코드(.text), 전역 데이터(.data, .bss), 힙 영역은 공통으로 사용됩니다. 
  하지만 각 스레드는 독립적인 스택을 가지고 있으며, 스택에는 해당 스레드의 함수 호출 정보, 지역 변수, 리턴 주소 등이 저장됩니다. 
  또한 각 스레드는 고유한 TCB(Thread Control Block)를 가지며, 이 구조체에는 스레드의 상태, 스택 포인터, 스케줄링 정보 등이 포함되어 있어 독립적인 실행이 가능하도록 합니다.
<li> "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.</li>
  스택(Stack) 영역은 함수 호출 시 생성되는 지역 변수나 매개변수 등이 저장되는 공간으로, 스택 자료구조처럼 후입선출(LIFO) 방식으로 동작합니다. 
  실제로 함수가 호출되면 스택 프레임이 쌓이고, 함수가 종료되면 가장 마지막에 쌓인 프레임부터 제거됩니다. 따라서 스택 영역은 스택 자료구조와 밀접한 연관이 있습니다.
  Heap의 Heap 자료구와 연관성이 없습니다. Heap의 경우 명시적으로 메모리 할당 및 해제할 수 있는 자유공간인 반면, Heap자료구조는 우선순위 Que를 위한 이진트리구조의 자료구조입니다.  
<li> IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요? </li>
  일반적으로 사용자 공간의 별도 매핑된 영역 또는 힙과 유사한 위치에 할당되며, shmget(), mmap() 등을 통해 커널이 할당한 메모리 블록을 프로세스 주소 공간에 매핑합니다. 
  이는 커널을 거치지 않고 두 프로세스가 직접 데이터를 주고받을 수 있게 하여, 파이프나 소켓보다 월등히 빠른 통신이 가능하게 하며, 대량의 데이터를 효율적으로 공유할 수 있게 해줍니다.
<li> 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요? </li>
  스택과 힙의 기본 크기는 컴파일러 및 운영체제에서 정해진 디폴트 값에 따라 초기화되며, 실제 크기는 런타임 중 동적으로 확장되거나 제한될 수 있습니다. 
  개발자는 코드에서 힙 크기를 명시적으로 제어할 수 있고, 스택 크기의 경우 pthread_attr_setstacksize() 같은 API를 통해 조정이 가능합니다. 
  일반 사용자도 ulimit -s 명령어를 통해 쉘에서 스택 크기를 설정할 수 있으며, 환경 변수나 실행 명령어의 인자로 힙의 크기를 변경할 수도 있습니다.
</ul>
</details>

<details>
  <summary><h3>5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.</h3></summary>
  스케줄러는 자원의 효율적 할당을 위해 특정 자원이나 작업을 특정 시점에 효율적으로 할당하거나 실행 순서를 관리하는 시스템이나 소프트웨어를 의미합니다.
  3종류로 나뉘는데 
  <장기 스케줄러>
    디스크에 존재하는 다수의 프로세스중 어떤 프로세스를 메모리로 저장할 지 결정합니다.
    프로새스 생성 여부, 시스템의 멀티프로그래밍의 수준을 결정합니다.
    사용빈도는 감소하는 추세이지만, 배치 시스템, 대형서버에서 유효 프로세스 제어시 사용합니다.
  <중기 스케줄러>
    메모리부족, 시스템 부하 분산의 이유로 현재 메모리의 프로세스를 일시적으로 디스크로 swap-out 하여 CPU에서 제외하는 역할을 합니다.
    이후 자원이 확보시, 다시 swap-in 되어 Ready 상태로 돌아옵니다.
  <단기 스케줄러>
    Ready Queue에 있는 프로세스 중 어떤 프로세스에게 CPU를 줄지 결정합니다. 반응 속도와 시스템 성능에 직접적인 영향을 주기 때문에, 가장 빠르고 자주 실행되는 스케줄러입니다.
<ul>
<li> 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?</li>
  현대의 범용 운영체제(예: Windows, Linux)에서는 단기 스케줄러는 필수적으로 사용되며, 장기 및 중기 스케줄러는 필요에 따라 생략되거나 통합된 형태로 존재합니다.

장기 스케줄러는 사용자나 시스템 관리자가 직접 실행을 제어하거나, 작업 큐를 기반으로 처리하기 때문에 명시적인 스케줄러 형태로는 거의 사용되지 않습니다.

중기 스케줄러는 메모리 관리 기법 중 하나인 Swapping 기법과 관련되며, 메모리 압박이 심한 경우에만 Paging과 함께 간접적으로 동작합니다.

결과적으로, 단기 스케줄러가 주로 활용되며, 나머지 두 스케줄러는 상황에 따라 간접적/자동으로 동작하거나 생략되는 구조입니다.
<li> 프로세스의 스케쥴링 상태에 대해 설명해 주세요.</li>
프로세스는 시스템 자원을 사용하며 **다양한 상태(State)**를 거치게 됩니다. 대표적인 상태는 다음과 같습니다:

New: 프로세스가 생성되고 준비 중인 상태

Ready: 실행 가능한 상태로 CPU 할당을 기다림

Running: CPU를 할당받아 실행 중

Waiting (또는 Blocked): 입출력 등의 이유로 대기 중이며, CPU를 사용할 수 없는 상태

Terminated: 실행을 완료하고 종료된 상태

추가로, 중기 스케줄러가 존재하는 시스템에서는 Suspended 상태도 고려됩니다:

Ready Suspended: 메모리 부족 등으로 인해 Ready 상태였지만 디스크로 swap-out 된 상태

Blocked Suspended: Blocked 상태에서 메모리에서 쫓겨난 상태

이러한 상태 전이는 스케줄러와 인터럽트, 시스템 호출 등을 통해 유기적으로 발생합니다.
<li> preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?</li>
Preemptive 스케줄링은 타이머 인터럽트나 우선순위 변경에 의해 운영체제가 실행 중인 프로세스를 강제로 CPU에서 제거하여 Ready 상태로 전이시킬 수 있습니다. 
반면 Non-preemptive 스케줄링은 프로세스가 I/O 요청이나 종료와 같은 자발적인 행위를 통해서만 CPU를 반환하므로, 운영체제에 의한 강제 선점이 불가능하여 Running → Ready 전이는 존재하지 않습니다. 
이로 인해 Non-preemptive 방식은 응답 시간 제어가 어렵지만, 컨텍스트 스위칭 비용이 적다는 장점이 있습니다.
<li> Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?</li>
메모리가 부족한 상황에서는 운영체제가 **프로세스를 메모리에서 제거(Swap out)**하여 디스크로 이동시키게 됩니다. 이때 프로세스는 다음과 같이 상태가 변경됩니다:

Ready → Ready Suspended

또는 Blocked → Blocked Suspended

이는 중기 스케줄러가 활성화된 경우이며, 해당 프로세스는 메모리 자원이 확보될 때까지 대기하게 됩니다. 이후 자원이 확보되면 swap-in되어 다시 Ready나 Blocked 상태로 전환됩니다.

현대 OS에서는 일반적으로 Paging 기법과 가상 메모리를 통해 물리 메모리 부족을 보완하며, 일부 페이지만 디스크로 옮기는 방식으로 처리하지만, 극단적인 메모리 부족 상황에서는 프로세스 전체를 swap하는 방식도 여전히 유효합니다.
</ul>
</details>

<details>
  <summary><h3>6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?</h3></summary>
<ul>
<li> 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?</li>
<li> 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?</li>
<li> 컨텍스트 스위칭은 언제 일어날까요?</li>
</ul>
</details>

<details>
  <summary><h3>7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?</h3></summary>
<ul>
<li> RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.</li>
<li> 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?</li>
<li> 동시성과 병렬성의 차이에 대해 설명해 주세요.</li>
<li> 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?</li>
<li> FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요? </li>
<li> 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?</li>
<li> 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?</li>
</ul>
</details>

<details>
  <summary><h3>8. 뮤텍스와 세마포어의 차이점은 무엇인가요?</h3></summary>
<ul>
<li> 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.</li>
<li> Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?</li> 
<li> 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?</li>
</ul>
</details>

<details>
  <summary><h3>9. Deadlock 에 대해 설명해 주세요.</h3></summary>
<ul>
<li> Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.</li>
<li> 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?</li>
<li> 어떤 방식으로 예방할 수 있을까요?</li>
<li> 왜 현대 OS는 Deadlock을 처리하지 않을까요?</li>
<li> Wait Free와 Lock Free를 비교해 주세요.</li>
</ul>
</details>

<details>
  <summary><h3>10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.</h3></summary>
<ul>
<li> 링커와, 로더의 차이에 대해 설명해 주세요.</li>
<li> 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.</li>
<li> JIT에 대해 설명해 주세요.</li>
<li> 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.</li>
<li> Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?</li>
<li> 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?</li>
</ul>
</details>

<details>
  <summary><h3>11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.</h3></summary>
<ul>
<li> Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.</li>
<li> 메시지 큐는 단방향이라고 할 수 있나요?</li>
</ul>
</details>

<details>
  <summary><h3>12. Thread Safe 하다는 것은 어떤 의미인가요?</h3></summary>
<ul>
<li> Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?</li>
<li> Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.</li>
<li> Race Condition 이 무엇인가요?</li>
<li> Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.</h3></summary>
<ul>
<li> Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요? </li>
<li> 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.</h3></summary>
<ul>
<li> 캐시 메모리는 어디에 위치해 있나요?</li>
<li> L1, L2 캐시에 대해 설명해 주세요.</li>
<li> 캐시에 올라오는 데이터는 어떻게 관리되나요?</li>
<li> 캐시간의 동기화는 어떻게 이루어지나요?</li>
<li> 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.</li>
<li> 캐시의 지역성에 대해 설명해 주세요.</li>
<li> 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.</li>
<li> 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?) </li>
</ul>
</details>

<details>
  <summary><h3>15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)</h3></summary>
<ul>
<li> worst-fit 은 언제 사용할 수 있을까요?</li>
<li> 성능이 가장 좋은 알고리즘은 무엇일까요?</li>
</ul>
</details>

<details>
  <summary><h3>16. Thrashing 이란 무엇인가요?</h3></summary>
<ul>
<li> Thrashing 발생 시, 어떻게 완화할 수 있을까요?</li>
</ul>
</details>

<details>
  <summary><h3>17. 가상 메모리란 무엇인가요?</h3></summary>
<ul>
<li> 가상 메모리가 가능한 이유가 무엇일까요?</li>
<li> Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.</li>
<li> 페이지 크기에 대한 Trade-Off를 설명해 주세요.</li>
<li> 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?</li>
<li> 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?</li>

</ul>
</details>

<details>
  <summary><h3>18. 세그멘테이션과 페이징의 차이점은 무엇인가요?</h3></summary>
<ul>
<li> 페이지와 프레임의 차이에 대해 설명해 주세요.</li>
<li> 내부 단편화와, 외부 단편화에 대해 설명해 주세요.</li>
<li> 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.</li>
<li> 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?</li>
<li> 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?</li>
<li> 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.</li>
<li> C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요? </li> 
</ul>
</details>

<details>
  <summary><h3>19. TLB는 무엇인가요?</h3></summary>
<ul>
<li> TLB를 쓰면 왜 빨라지나요?</li>
<li> MMU가 무엇인가요?</li>
<li> TLB와 MMU는 어디에 위치해 있나요?</li>
<li> 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요? </li>
<li> TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요. </li>
</ul>
</details>

<details>
  <summary><h3>20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.</h3></summary>
<ul>
<li> volatile 키워드는 어떤 의미가 있나요?</li>
<li> 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?</li>
<li> 
</ul>
</details>

<details>
  <summary><h3>21. 페이지 교체 알고리즘에 대해 설명해 주세요.</h3></summary>
<ul>
<li> LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?</li>
<li> LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?</li>
<li> LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.</li>
</ul>
</details>

<details>
  <summary><h3>22. File Descriptor와, File System에 에 대해 설명해 주세요.</h3></summary>
<ul>
<li> I-Node가 무엇인가요?</li>
<li> 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?</li>
</ul>
</details>

<details>
  <summary><h3>23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.</h3></summary>
<ul>
<li> 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?</li>
<li> I/O 멀티플렉싱에 대해 설명해 주세요.</li>
<li> 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요? </li>
</ul>
</details>
